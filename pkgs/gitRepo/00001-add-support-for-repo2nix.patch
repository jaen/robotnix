From 8fe8a2efaa6bcd404c256a29d1dc5ed4ae241a08 Mon Sep 17 00:00:00 2001
From: ajs124 <git@ajs124.de>
Date: Tue, 26 Feb 2019 04:48:13 +0100
Subject: [PATCH 01/16] add initial (hacky) version of "repo2nix"

now with less impurities
---
 project.py     |   4 +-
 subcmds/nix.py | 100 +++++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 102 insertions(+), 2 deletions(-)
 create mode 100644 subcmds/nix.py

diff --git a/project.py b/project.py
index 1f5e4c3..c3c3384 100644
--- a/project.py
+++ b/project.py
@@ -2887,8 +2887,8 @@ class Project:
                 )
 
     def _LsRemote(self, refs):
-        cmd = ["ls-remote", self.remote.name, refs]
-        p = GitCommand(self, cmd, capture_stdout=True)
+        cmd = ["ls-remote", self.remote.url, refs]
+        p = GitCommand(self, cmd, cwd="/", capture_stdout=True)
         if p.Wait() == 0:
             return p.stdout
         return None
diff --git a/subcmds/nix.py b/subcmds/nix.py
new file mode 100644
index 0000000..f113ede
--- /dev/null
+++ b/subcmds/nix.py
@@ -0,0 +1,100 @@
+#
+# Copyright (C) 2008 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from __future__ import print_function
+
+from pyversion import is_python3
+if is_python3():
+  import http.cookiejar as cookielib
+  import urllib.error
+  import urllib.parse
+  import urllib.request
+  import xmlrpc.client
+else:
+  import imp
+  import urllib2
+  import urlparse
+  import xmlrpclib
+  urllib = imp.new_module('urllib')
+  urllib.error = urllib2
+  urllib.parse = urlparse
+  urllib.request = urllib2
+  xmlrpc = imp.new_module('xmlrpc')
+  xmlrpc.client = xmlrpclib
+
+try:
+  import threading as _threading
+except ImportError:
+  import dummy_threading as _threading
+
+try:
+  import resource
+  def _rlimit_nofile():
+    return resource.getrlimit(resource.RLIMIT_NOFILE)
+except ImportError:
+  def _rlimit_nofile():
+    return (256, 256)
+
+try:
+  import multiprocessing
+except ImportError:
+  multiprocessing = None
+
+from command import Command, MirrorSafeCommand
+
+class Nix(Command, MirrorSafeCommand):
+  common = True
+  helpSummary = "Export nix file with sources"
+  helpUsage = """
+%prog [<project>...]
+"""
+  helpDescription = """
+"""
+
+  def Execute(self, opt, args):
+    all_projects = self.GetProjects(args, missing_ok=True, submodules_ok=False)
+
+    oS = '{\n'
+    oS += "unpackPhase = ''\n" \
+    'echo "reassembling source tree from git source store paths"\n' \
+    'mkdir src; cd src\n' \
+    'for src in $srcs; do\n' \
+    " dest_folder=$(stripHash $src); dest_folder=''${dest_folder//=//}\n" \
+    ' echo "$src -> $dest_folder"\n' \
+    ' mkdir -p "$dest_folder"\n' \
+    ' cp --reflink=auto --no-preserve=ownership --no-dereference --preserve=links --recursive "$src/." "$dest_folder/"\n' \
+    ' chmod -R u+w "$dest_folder"\n' \
+    'done\n' \
+    'echo "creating symlinks and copies as specified in repo manifest(s)"\n'
+    for p in all_projects:
+      for f in p.linkfiles:
+        oS += 'ln -s ' + f.src_rel_to_dest + ' ' + f.dest + '\n'
+      for c in p.copyfiles:
+        oS += 'cp --reflink=auto ' + p.relpath + '/' + c.src + ' ' + c.dest + '\n'
+    oS += "'';\n"
+
+    oS += 'sources = [\n'
+    for p in all_projects:
+      oS += '  (builtins.fetchGit {\n'
+      oS += '    url = "' + p.remote.url + '";\n'
+      if 'refs/heads' in p.revisionExpr:
+        oS += '    ref = "' + p.revisionExpr.split('/')[-1] + '";\n'
+      else:
+        oS += '    ref = "' + p.revisionExpr + '";\n'
+      oS += '    rev = "' + p._LsRemote(p.revisionExpr).split('\t')[0] + '";\n'
+      oS += '    name = "' + p.relpath.replace('/', '=') + '";\n'
+      oS += '  })\n'
+    oS += '];\n}'
+    print(oS)
\ No newline at end of file
-- 
2.44.0


From 4550efa07636b497bfca0b8379c0656ed09770cb Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Mon, 15 Jul 2019 14:43:17 -0400
Subject: [PATCH 02/16] repo2nix: output just json--do more processing in nix

---
 subcmds/dumpjson.py | 92 +++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 92 insertions(+)
 create mode 100644 subcmds/dumpjson.py

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
new file mode 100644
index 0000000..a09885d
--- /dev/null
+++ b/subcmds/dumpjson.py
@@ -0,0 +1,92 @@
+#
+# Copyright (C) 2008 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+from __future__ import print_function
+
+from pyversion import is_python3
+if is_python3():
+  import http.cookiejar as cookielib
+  import urllib.error
+  import urllib.parse
+  import urllib.request
+  import xmlrpc.client
+else:
+  import imp
+  import urllib2
+  import urlparse
+  import xmlrpclib
+  urllib = imp.new_module('urllib')
+  urllib.error = urllib2
+  urllib.parse = urlparse
+  urllib.request = urllib2
+  xmlrpc = imp.new_module('xmlrpc')
+  xmlrpc.client = xmlrpclib
+
+try:
+  import threading as _threading
+except ImportError:
+  import dummy_threading as _threading
+
+try:
+  import resource
+  def _rlimit_nofile():
+    return resource.getrlimit(resource.RLIMIT_NOFILE)
+except ImportError:
+  def _rlimit_nofile():
+    return (256, 256)
+
+try:
+  import multiprocessing
+except ImportError:
+  multiprocessing = None
+
+from command import Command, MirrorSafeCommand
+
+class Dumpjson(Command, MirrorSafeCommand):
+  common = True
+  helpSummary = "Export json file with sources"
+  helpUsage = """
+%prog [<project>...]
+"""
+  helpDescription = """
+"""
+
+  def Execute(self, opt, args):
+    all_projects = self.GetProjects(args, missing_ok=True, submodules_ok=False)
+
+    import json
+    data = {
+        p.name: {
+            "url": p.remote.url,
+            "relpath": p.relpath,
+            "groups": p.groups,
+            "revisionExpr": p.revisionExpr,
+            "rev": p._LsRemote(p.revisionExpr).split('\t')[0],
+            "linkfiles": [
+                { "src_rel_to_dest": l.src_rel_to_dest,
+                 "dest": l.dest,
+                 }
+                for l in p.linkfiles
+            ],
+            "copyfiles": [
+                { "src": c.src,
+                 "dest": c.dest,
+                 }
+                for c in p.copyfiles
+            ],
+        }
+        for p in all_projects
+    };
+    print(json.dumps(data))
-- 
2.44.0


From 333fc9d324640adb94e2ec7b51ab24268a3084d4 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Janne=20He=C3=9F?= <janne@hess.ooo>
Date: Sun, 27 Oct 2019 11:31:40 +0100
Subject: [PATCH 03/16] nix: Retry 20 times if the http request fails

---
 subcmds/nix.py | 9 +++++++--
 1 file changed, 7 insertions(+), 2 deletions(-)

diff --git a/subcmds/nix.py b/subcmds/nix.py
index f113ede..fd7c188 100644
--- a/subcmds/nix.py
+++ b/subcmds/nix.py
@@ -53,6 +53,7 @@ except ImportError:
   multiprocessing = None
 
 from command import Command, MirrorSafeCommand
+from itertools import repeat
 
 class Nix(Command, MirrorSafeCommand):
   common = True
@@ -93,8 +94,12 @@ class Nix(Command, MirrorSafeCommand):
         oS += '    ref = "' + p.revisionExpr.split('/')[-1] + '";\n'
       else:
         oS += '    ref = "' + p.revisionExpr + '";\n'
-      oS += '    rev = "' + p._LsRemote(p.revisionExpr).split('\t')[0] + '";\n'
+      while repeat(None, 20):
+        raw_rev = p._LsRemote(p.revisionExpr)
+        if raw_rev != None:
+          break
+      oS += '    rev = "' + raw_rev.split('\t')[0] + '";\n'
       oS += '    name = "' + p.relpath.replace('/', '=') + '";\n'
       oS += '  })\n'
     oS += '];\n}'
-    print(oS)
\ No newline at end of file
+    print(oS)
-- 
2.44.0


From 991502c597e3d3c9d5b25fcf08ecd216fdba107b Mon Sep 17 00:00:00 2001
From: ajs124 <git@ajs124.de>
Date: Tue, 3 Dec 2019 20:23:01 +0100
Subject: [PATCH 04/16] fml

---
 subcmds/nix.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/subcmds/nix.py b/subcmds/nix.py
index fd7c188..ad1f19f 100644
--- a/subcmds/nix.py
+++ b/subcmds/nix.py
@@ -98,7 +98,7 @@ class Nix(Command, MirrorSafeCommand):
         raw_rev = p._LsRemote(p.revisionExpr)
         if raw_rev != None:
           break
-      oS += '    rev = "' + raw_rev.split('\t')[0] + '";\n'
+      # oS += '    rev = "' + raw_rev.split('\t')[0] + '";\n'
       oS += '    name = "' + p.relpath.replace('/', '=') + '";\n'
       oS += '  })\n'
     oS += '];\n}'
-- 
2.44.0


From 07d83a29279874566234b2a3aed6fc270e5f9b8b Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Tue, 3 Dec 2019 16:56:27 -0500
Subject: [PATCH 05/16] dumpjson: Sort json output by keys for reproducibility

---
 subcmds/dumpjson.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index a09885d..8997c27 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -89,4 +89,4 @@ class Dumpjson(Command, MirrorSafeCommand):
         }
         for p in all_projects
     };
-    print(json.dumps(data))
+    print(json.dumps(data, sort_keys=True))
-- 
2.44.0


From 40465bd1ec05fa648765a0bc5d3ed461ae8ce2e2 Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Sat, 7 Dec 2019 12:15:55 -0500
Subject: [PATCH 06/16] dumpjson: parallelize

---
 subcmds/dumpjson.py | 19 +++++++++++++++++--
 1 file changed, 17 insertions(+), 2 deletions(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index 8997c27..18aca4c 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -52,8 +52,15 @@ try:
 except ImportError:
   multiprocessing = None
 
+import sys
+import json
+
 from command import Command, MirrorSafeCommand
 
+def _fetch_revs(p, sem):
+    with sem:
+        p.rev = p._LsRemote(p.revisionExpr).split('\t')[0]
+
 class Dumpjson(Command, MirrorSafeCommand):
   common = True
   helpSummary = "Export json file with sources"
@@ -66,14 +73,22 @@ class Dumpjson(Command, MirrorSafeCommand):
   def Execute(self, opt, args):
     all_projects = self.GetProjects(args, missing_ok=True, submodules_ok=False)
 
-    import json
+    MAX_THREADS = 8
+    sem = _threading.Semaphore(MAX_THREADS)
+
+    threads = [ _threading.Thread(target=_fetch_revs, args=(p, sem)) for p in all_projects ]
+    for t in threads:
+        t.start()
+    for t in threads:
+        t.join()
+
     data = {
         p.name: {
             "url": p.remote.url,
             "relpath": p.relpath,
             "groups": p.groups,
             "revisionExpr": p.revisionExpr,
-            "rev": p._LsRemote(p.revisionExpr).split('\t')[0],
+            "rev": p.rev,
             "linkfiles": [
                 { "src_rel_to_dest": l.src_rel_to_dest,
                  "dest": l.dest,
-- 
2.44.0


From 92f28fed56d9195cf723aef22b3ce00b47742ed1 Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Sun, 8 Dec 2019 14:21:32 -0500
Subject: [PATCH 07/16] dumpjson: Sort groups list

---
 subcmds/dumpjson.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index 18aca4c..a1da03c 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -86,7 +86,7 @@ class Dumpjson(Command, MirrorSafeCommand):
         p.name: {
             "url": p.remote.url,
             "relpath": p.relpath,
-            "groups": p.groups,
+            "groups": sorted(p.groups),
             "revisionExpr": p.revisionExpr,
             "rev": p.rev,
             "linkfiles": [
-- 
2.44.0


From 35c3b4c59382e7db182b4eedfacba55c762295e5 Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Tue, 14 Apr 2020 19:47:47 -0400
Subject: [PATCH 08/16] dumpjson: fix explicitly referencing a revision

GrapheneOS does this as of QQ2A.200405.005.2020.04.13.21
---
 subcmds/dumpjson.py | 11 +++++++++--
 1 file changed, 9 insertions(+), 2 deletions(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index a1da03c..8ca9d08 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -54,12 +54,19 @@ except ImportError:
 
 import sys
 import json
+import re
 
 from command import Command, MirrorSafeCommand
 
 def _fetch_revs(p, sem):
-    with sem:
-        p.rev = p._LsRemote(p.revisionExpr).split('\t')[0]
+    if re.match("[0-9a-f]{40}", p.revisionExpr):
+        # Use revisionExpr if it is already a SHA1 hash
+        p.rev = p.revisionExpr
+    else:
+        # Otherwise we need to grab the hash from the remote source
+        with sem:
+            p.rev = p._LsRemote(p.revisionExpr).split('\t')[0]
+            assert p.rev != ""
 
 class Dumpjson(Command, MirrorSafeCommand):
   common = True
-- 
2.44.0


From 35c373392754b6e79f1ef20a395b97d6a736ba92 Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Wed, 15 Apr 2020 13:05:14 -0400
Subject: [PATCH 09/16] dumpjson: fix removed LinkFile attribute

This unfortunately also changes the output schema for dumpjson.
---
 subcmds/dumpjson.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index 8ca9d08..726ccfd 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -97,7 +97,7 @@ class Dumpjson(Command, MirrorSafeCommand):
             "revisionExpr": p.revisionExpr,
             "rev": p.rev,
             "linkfiles": [
-                { "src_rel_to_dest": l.src_rel_to_dest,
+                { "src": l.src,
                  "dest": l.dest,
                  }
                 for l in p.linkfiles
-- 
2.44.0


From 71a828d0123b6fe16c1ca5a869c49d55c8dc275b Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Wed, 15 Apr 2020 13:10:13 -0400
Subject: [PATCH 10/16] dumpjson: filter out groups with redundant information

---
 subcmds/dumpjson.py | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index 726ccfd..0bd2708 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -89,11 +89,12 @@ class Dumpjson(Command, MirrorSafeCommand):
     for t in threads:
         t.join()
 
+    group_filter = lambda g: not (g == "all" or g.startswith("name:") or g.startswith("path:"))
     data = {
         p.name: {
             "url": p.remote.url,
             "relpath": p.relpath,
-            "groups": sorted(p.groups),
+            "groups": sorted(filter(group_filter, p.groups)),
             "revisionExpr": p.revisionExpr,
             "rev": p.rev,
             "linkfiles": [
-- 
2.44.0


From 0dde9323fa9480efcf68e2d5f0208e51a2e001c8 Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Wed, 15 Apr 2020 13:16:05 -0400
Subject: [PATCH 11/16] dumpjson: conditionally exclude empty attributes

---
 subcmds/dumpjson.py | 29 +++++++++++------------------
 1 file changed, 11 insertions(+), 18 deletions(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index 0bd2708..176391c 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -89,27 +89,20 @@ class Dumpjson(Command, MirrorSafeCommand):
     for t in threads:
         t.join()
 
-    group_filter = lambda g: not (g == "all" or g.startswith("name:") or g.startswith("path:"))
-    data = {
-        p.name: {
+    data = {}
+    for p in all_projects:
+        data[p.name] = {
             "url": p.remote.url,
             "relpath": p.relpath,
-            "groups": sorted(filter(group_filter, p.groups)),
             "revisionExpr": p.revisionExpr,
             "rev": p.rev,
-            "linkfiles": [
-                { "src": l.src,
-                 "dest": l.dest,
-                 }
-                for l in p.linkfiles
-            ],
-            "copyfiles": [
-                { "src": c.src,
-                 "dest": c.dest,
-                 }
-                for c in p.copyfiles
-            ],
         }
-        for p in all_projects
-    };
+        filtered_groups = filter(lambda g: not (g == "all" or g.startswith("name:") or g.startswith("path:")), p.groups)
+        if filtered_groups:
+            data[p.name]["groups"] = sorted(filtered_groups)
+        if p.linkfiles:
+            data[p.name]["linkfiles"] = [ { "src": l.src, "dest": l.dest } for l in p.linkfiles ]
+        if p.copyfiles:
+            data[p.name]["copyfiles"] = [ { "src": c.src, "dest": c.dest } for c in p.copyfiles ]
+
     print(json.dumps(data, sort_keys=True))
-- 
2.44.0


From 5af943e5b9378220db65d5a2acc1f4b6f6fe409d Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Thu, 16 Apr 2020 14:15:52 -0400
Subject: [PATCH 12/16] dumpjson: schema change to use relpath as keys

---
 subcmds/dumpjson.py | 9 ++++-----
 1 file changed, 4 insertions(+), 5 deletions(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index 176391c..2105002 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -91,18 +91,17 @@ class Dumpjson(Command, MirrorSafeCommand):
 
     data = {}
     for p in all_projects:
-        data[p.name] = {
+        data[p.relpath] = {
             "url": p.remote.url,
-            "relpath": p.relpath,
             "revisionExpr": p.revisionExpr,
             "rev": p.rev,
         }
         filtered_groups = filter(lambda g: not (g == "all" or g.startswith("name:") or g.startswith("path:")), p.groups)
         if filtered_groups:
-            data[p.name]["groups"] = sorted(filtered_groups)
+            data[p.relpath]["groups"] = sorted(filtered_groups)
         if p.linkfiles:
-            data[p.name]["linkfiles"] = [ { "src": l.src, "dest": l.dest } for l in p.linkfiles ]
+            data[p.relpath]["linkfiles"] = [ { "src": l.src, "dest": l.dest } for l in p.linkfiles ]
         if p.copyfiles:
-            data[p.name]["copyfiles"] = [ { "src": c.src, "dest": c.dest } for c in p.copyfiles ]
+            data[p.relpath]["copyfiles"] = [ { "src": c.src, "dest": c.dest } for c in p.copyfiles ]
 
     print(json.dumps(data, sort_keys=True))
-- 
2.44.0


From 3edd5009f6f0d2b6aa64b81246ffeb1bfb7405d6 Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Sat, 11 Jul 2020 11:08:14 -0700
Subject: [PATCH 13/16] dumpjson: use -j to set number of threads

---
 subcmds/dumpjson.py | 9 ++++++---
 1 file changed, 6 insertions(+), 3 deletions(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index 2105002..4648e10 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -77,12 +77,15 @@ class Dumpjson(Command, MirrorSafeCommand):
   helpDescription = """
 """
 
+  def _Options(self, p):
+    p.add_option('-j', '--jobs',
+                 dest='jobs', action='store', type='int', default=8,
+                 help="number of projects to check simultaneously")
+
   def Execute(self, opt, args):
     all_projects = self.GetProjects(args, missing_ok=True, submodules_ok=False)
 
-    MAX_THREADS = 8
-    sem = _threading.Semaphore(MAX_THREADS)
-
+    sem = _threading.Semaphore(opt.jobs)
     threads = [ _threading.Thread(target=_fetch_revs, args=(p, sem)) for p in all_projects ]
     for t in threads:
         t.start()
-- 
2.44.0


From 394b8dd50c263b18561386a85bf5294fda1fa5a2 Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Sat, 11 Jul 2020 11:25:38 -0700
Subject: [PATCH 14/16] dumpjson: add a "local_only" option for offline
 processing

---
 subcmds/dumpjson.py | 38 ++++++++++++++++++++++++--------------
 1 file changed, 24 insertions(+), 14 deletions(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index 4648e10..bbb4245 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -59,14 +59,9 @@ import re
 from command import Command, MirrorSafeCommand
 
 def _fetch_revs(p, sem):
-    if re.match("[0-9a-f]{40}", p.revisionExpr):
-        # Use revisionExpr if it is already a SHA1 hash
-        p.rev = p.revisionExpr
-    else:
-        # Otherwise we need to grab the hash from the remote source
-        with sem:
-            p.rev = p._LsRemote(p.revisionExpr).split('\t')[0]
-            assert p.rev != ""
+  with sem:
+      p.rev = p._LsRemote(p.revisionExpr).split('\t')[0]
+      assert p.rev != ""
 
 class Dumpjson(Command, MirrorSafeCommand):
   common = True
@@ -81,16 +76,31 @@ class Dumpjson(Command, MirrorSafeCommand):
     p.add_option('-j', '--jobs',
                  dest='jobs', action='store', type='int', default=8,
                  help="number of projects to check simultaneously")
+    p.add_option('-l', '--local-only',
+                 dest='local_only', action='store_true',
+                 help="don't fetch project revisions even if they are missing")
 
   def Execute(self, opt, args):
     all_projects = self.GetProjects(args, missing_ok=True, submodules_ok=False)
 
-    sem = _threading.Semaphore(opt.jobs)
-    threads = [ _threading.Thread(target=_fetch_revs, args=(p, sem)) for p in all_projects ]
-    for t in threads:
-        t.start()
-    for t in threads:
-        t.join()
+    # Fill out rev if we already have the information available
+    to_fetch = []
+    for p in all_projects:
+      if re.match("[0-9a-f]{40}", p.revisionExpr):
+          # Use revisionExpr if it is already a SHA1 hash
+          p.rev = p.revisionExpr
+      else:
+        p.rev = None
+        to_fetch.append(p)
+
+    if not opt.local_only:
+      # Fetch rev for projects we don't know yet
+      sem = _threading.Semaphore(opt.jobs)
+      threads = [ _threading.Thread(target=_fetch_revs, args=(p, sem)) for p in to_fetch ]
+      for t in threads:
+          t.start()
+      for t in threads:
+          t.join()
 
     data = {}
     for p in all_projects:
-- 
2.44.0


From 8224ebd83cfecde0736f5905889188cf652cff24 Mon Sep 17 00:00:00 2001
From: Daniel Fullmer <danielrf12@gmail.com>
Date: Wed, 3 Feb 2021 18:56:31 -0800
Subject: [PATCH 15/16] dumpjson: no longers output rev attribute

Moved logic into robotnix mk-repo-file.py script
---
 subcmds/dumpjson.py | 32 +-------------------------------
 1 file changed, 1 insertion(+), 31 deletions(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index bbb4245..870e269 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -58,11 +58,6 @@ import re
 
 from command import Command, MirrorSafeCommand
 
-def _fetch_revs(p, sem):
-  with sem:
-      p.rev = p._LsRemote(p.revisionExpr).split('\t')[0]
-      assert p.rev != ""
-
 class Dumpjson(Command, MirrorSafeCommand):
   common = True
   helpSummary = "Export json file with sources"
@@ -73,41 +68,16 @@ class Dumpjson(Command, MirrorSafeCommand):
 """
 
   def _Options(self, p):
-    p.add_option('-j', '--jobs',
-                 dest='jobs', action='store', type='int', default=8,
-                 help="number of projects to check simultaneously")
-    p.add_option('-l', '--local-only',
-                 dest='local_only', action='store_true',
-                 help="don't fetch project revisions even if they are missing")
+    pass
 
   def Execute(self, opt, args):
     all_projects = self.GetProjects(args, missing_ok=True, submodules_ok=False)
 
-    # Fill out rev if we already have the information available
-    to_fetch = []
-    for p in all_projects:
-      if re.match("[0-9a-f]{40}", p.revisionExpr):
-          # Use revisionExpr if it is already a SHA1 hash
-          p.rev = p.revisionExpr
-      else:
-        p.rev = None
-        to_fetch.append(p)
-
-    if not opt.local_only:
-      # Fetch rev for projects we don't know yet
-      sem = _threading.Semaphore(opt.jobs)
-      threads = [ _threading.Thread(target=_fetch_revs, args=(p, sem)) for p in to_fetch ]
-      for t in threads:
-          t.start()
-      for t in threads:
-          t.join()
-
     data = {}
     for p in all_projects:
         data[p.relpath] = {
             "url": p.remote.url,
             "revisionExpr": p.revisionExpr,
-            "rev": p.rev,
         }
         filtered_groups = filter(lambda g: not (g == "all" or g.startswith("name:") or g.startswith("path:")), p.groups)
         if filtered_groups:
-- 
2.44.0


From dca531f6d6e9fdcf00aa9d18f0153bd66a2e32ea Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Tomek=20Ma=C5=84ko?= <tomek.manko@railgun-solutions.com>
Date: Fri, 24 May 2024 21:35:57 +0200
Subject: [PATCH 16/16] Remove python3 conditionals

---
 subcmds/dumpjson.py | 23 +++++------------------
 subcmds/nix.py      | 23 +++++------------------
 2 files changed, 10 insertions(+), 36 deletions(-)

diff --git a/subcmds/dumpjson.py b/subcmds/dumpjson.py
index 870e269..7dfc465 100644
--- a/subcmds/dumpjson.py
+++ b/subcmds/dumpjson.py
@@ -15,24 +15,11 @@
 
 from __future__ import print_function
 
-from pyversion import is_python3
-if is_python3():
-  import http.cookiejar as cookielib
-  import urllib.error
-  import urllib.parse
-  import urllib.request
-  import xmlrpc.client
-else:
-  import imp
-  import urllib2
-  import urlparse
-  import xmlrpclib
-  urllib = imp.new_module('urllib')
-  urllib.error = urllib2
-  urllib.parse = urlparse
-  urllib.request = urllib2
-  xmlrpc = imp.new_module('xmlrpc')
-  xmlrpc.client = xmlrpclib
+import http.cookiejar as cookielib
+import urllib.error
+import urllib.parse
+import urllib.request
+import xmlrpc.client
 
 try:
   import threading as _threading
diff --git a/subcmds/nix.py b/subcmds/nix.py
index ad1f19f..51be288 100644
--- a/subcmds/nix.py
+++ b/subcmds/nix.py
@@ -15,24 +15,11 @@
 
 from __future__ import print_function
 
-from pyversion import is_python3
-if is_python3():
-  import http.cookiejar as cookielib
-  import urllib.error
-  import urllib.parse
-  import urllib.request
-  import xmlrpc.client
-else:
-  import imp
-  import urllib2
-  import urlparse
-  import xmlrpclib
-  urllib = imp.new_module('urllib')
-  urllib.error = urllib2
-  urllib.parse = urlparse
-  urllib.request = urllib2
-  xmlrpc = imp.new_module('xmlrpc')
-  xmlrpc.client = xmlrpclib
+import http.cookiejar as cookielib
+import urllib.error
+import urllib.parse
+import urllib.request
+import xmlrpc.client
 
 try:
   import threading as _threading
-- 
2.44.0

